{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ICP8.ipynb",
      "provenance": [],
      "authorship_tag": "ABX9TyMGFVg0nP1kvdqJVrB3xsZh",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dhairyachandra/KDM_Spring_2021/blob/main/ICP_8/Source/ICP8.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TwvmHMzaNp8H"
      },
      "source": [
        "!pip install textacy\n",
        "import spacy\n",
        "import textacy"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M1oaMGkgN73L"
      },
      "source": [
        "# reading input files\n",
        "f = open('text1.txt', 'r')\n",
        "# loading en_core_web_sm model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(f.read())\n",
        "f.close()"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EUwSZYOQNrxY"
      },
      "source": [
        "for token in doc:\n",
        "    print(token.text, token.pos_, token.dep_)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_NPYrvHwN4uC"
      },
      "source": [
        "tuples_list = []\n",
        "\n",
        "#extracting triplet using textacy library\n",
        "tuples = textacy.extract.subject_verb_object_triples(doc)\n",
        "tuples_to_list = list(tuples)\n",
        "if tuples_to_list != []:\n",
        "    tuples_list.append(tuples_to_list)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "G_yofTMBOLIJ",
        "outputId": "f16fabda-73be-4325-9ccf-85f107ab0a41"
      },
      "source": [
        "for pair in tuples_list[0]:\n",
        "    print(pair)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(that, have devastated, parts)\n",
            "(temperatures, are having, impact)\n",
            "(snow, are having, impact)\n",
            "(ice, are having, impact)\n",
            "(we, might expect, to see)\n",
            "(Health Officials, told, CNN)\n",
            "(government, was encouraging, governors)\n",
            "(government, was encouraging, to extend)\n",
            "(government, was encouraging, partners)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZKZZWg2OcMP"
      },
      "source": [
        "## Text 2"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xsoULmdQONoK"
      },
      "source": [
        "# reading input files\n",
        "f = open('text2.txt', 'r')\n",
        "# loading en_core_web_sm model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(f.read())\n",
        "f.close()"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ocxDwwdOfQa",
        "outputId": "98b6ba89-c3cc-4edf-d03c-88b74764bb77"
      },
      "source": [
        "tuples_list = []\n",
        "\n",
        "#extracting triplet using textacy library\n",
        "tuples = textacy.extract.subject_verb_object_triples(doc)\n",
        "tuples_to_list = list(tuples)\n",
        "if tuples_to_list != []:\n",
        "    tuples_list.append(tuples_to_list)\n",
        "\n",
        "for pair in tuples_list[0]:\n",
        "    print(pair)"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Lenovo, kicked, home journey)\n",
            "(company, launched, Essential)\n",
            "(Lenovo, has launched, device)\n",
            "(me, give, you)\n",
            "(me, give, overview)\n",
            "(It, features, LED panel)\n",
            "(which, does not support, touch input)\n",
            "(It, can show, you)\n",
            "(It, can show, time)\n",
            "(device, supports, Assistant)\n",
            "(you, use, Essential)\n",
            "(device, will play, media)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lPxBWWosOmBN"
      },
      "source": [
        "## Text 3"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "85n_GEjOOhxN"
      },
      "source": [
        "# reading input files\n",
        "f = open('text3.txt', 'r')\n",
        "# loading en_core_web_sm model\n",
        "\n",
        "nlp = spacy.load(\"en_core_web_sm\")\n",
        "doc = nlp(f.read())\n",
        "f.close()"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jA7u3SfaOpoE",
        "outputId": "51c5ecc8-4d3c-47dd-d1c4-2fe6eeef2d82"
      },
      "source": [
        "tuples_list = []\n",
        "\n",
        "#extracting triplet using textacy library\n",
        "tuples = textacy.extract.subject_verb_object_triples(doc)\n",
        "tuples_to_list = list(tuples)\n",
        "if tuples_to_list != []:\n",
        "    tuples_list.append(tuples_to_list)\n",
        "\n",
        "for pair in tuples_list[0]:\n",
        "    print(pair)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(Pro, has won, title)\n",
            "(M Science, tracks, sales)\n",
            "(series, topped, surveys)\n",
            "(S20, follow, iPhones)\n",
            "(Note, follow, iPhones)\n",
            "(G, joining, mini)\n",
            "(report, states, that)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AR_tGuWmOrUH"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}